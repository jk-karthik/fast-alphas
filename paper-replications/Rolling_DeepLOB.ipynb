{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edc3eb4a-8827-48e5-8077-2ee36668bef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torchinfo import summary\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import copy\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0f45169-1d08-47b0-a8c9-522e05adf267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macOS-14.6-arm64-arm-64bit\n"
     ]
    }
   ],
   "source": [
    "import platform; print(platform.platform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00ba2d46-f624-42fd-b8d5-a3a25af76d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/jandh/Desktop/Old Desktop/od/1 quater/Project Lab/labelled_data_500.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f627fcf5-ead6-42a4-ad60-7cc3d56b9f91",
   "metadata": {},
   "outputs": [],
   "source": [
    " x = pd.to_datetime(df['date']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f8aae01-61a2-4e93-b187-926f654e4d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2021-06-01', '2021-06-02', '2021-06-03', '2021-06-04',\n",
       "               '2021-06-07', '2021-06-08', '2021-06-09', '2021-06-10',\n",
       "               '2021-06-11', '2021-06-15', '2021-06-16', '2021-06-17',\n",
       "               '2021-06-18', '2021-06-21', '2021-06-22'],\n",
       "              dtype='datetime64[ns]', name='date', freq=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.sort_index() .index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7113e21-5e7b-4ef5-a105-4786b219d626",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = df[pd.to_datetime(df['date']) <= pd.to_datetime('2021-06-07')]\n",
    "test_data = df[pd.to_datetime(df['date']) == pd.to_datetime('2021-06-08')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7daf870a-f4f0-48ad-a62b-5a667d7cc744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>SP1</th>\n",
       "      <th>SV1</th>\n",
       "      <th>BP1</th>\n",
       "      <th>BV1</th>\n",
       "      <th>SP2</th>\n",
       "      <th>SV2</th>\n",
       "      <th>BP2</th>\n",
       "      <th>BV2</th>\n",
       "      <th>SP3</th>\n",
       "      <th>...</th>\n",
       "      <th>BV3</th>\n",
       "      <th>SP4</th>\n",
       "      <th>SV4</th>\n",
       "      <th>BP4</th>\n",
       "      <th>BV4</th>\n",
       "      <th>SP5</th>\n",
       "      <th>SV5</th>\n",
       "      <th>BP5</th>\n",
       "      <th>BV5</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>10200.0</td>\n",
       "      <td>3294</td>\n",
       "      <td>10150.0</td>\n",
       "      <td>61</td>\n",
       "      <td>10250.0</td>\n",
       "      <td>2185</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>1240</td>\n",
       "      <td>10300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1403</td>\n",
       "      <td>10350.0</td>\n",
       "      <td>2138</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2195</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>2596</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>685</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>10200.0</td>\n",
       "      <td>3294</td>\n",
       "      <td>10150.0</td>\n",
       "      <td>59</td>\n",
       "      <td>10250.0</td>\n",
       "      <td>2185</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>1240</td>\n",
       "      <td>10300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1403</td>\n",
       "      <td>10350.0</td>\n",
       "      <td>2138</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2195</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>2596</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>685</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>10200.0</td>\n",
       "      <td>3324</td>\n",
       "      <td>10150.0</td>\n",
       "      <td>59</td>\n",
       "      <td>10250.0</td>\n",
       "      <td>2185</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>1240</td>\n",
       "      <td>10300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1403</td>\n",
       "      <td>10350.0</td>\n",
       "      <td>2138</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2195</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>2596</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>685</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>10200.0</td>\n",
       "      <td>3324</td>\n",
       "      <td>10150.0</td>\n",
       "      <td>43</td>\n",
       "      <td>10250.0</td>\n",
       "      <td>2185</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>1240</td>\n",
       "      <td>10300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1403</td>\n",
       "      <td>10350.0</td>\n",
       "      <td>2138</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2195</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>2596</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>685</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>10200.0</td>\n",
       "      <td>3324</td>\n",
       "      <td>10150.0</td>\n",
       "      <td>43</td>\n",
       "      <td>10250.0</td>\n",
       "      <td>2185</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>1240</td>\n",
       "      <td>10300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1403</td>\n",
       "      <td>10350.0</td>\n",
       "      <td>2138</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2195</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>2596</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>687</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date      SP1   SV1      BP1  BV1      SP2   SV2      BP2   BV2  \\\n",
       "0  2021-06-01  10200.0  3294  10150.0   61  10250.0  2185  10100.0  1240   \n",
       "1  2021-06-01  10200.0  3294  10150.0   59  10250.0  2185  10100.0  1240   \n",
       "2  2021-06-01  10200.0  3324  10150.0   59  10250.0  2185  10100.0  1240   \n",
       "3  2021-06-01  10200.0  3324  10150.0   43  10250.0  2185  10100.0  1240   \n",
       "4  2021-06-01  10200.0  3324  10150.0   43  10250.0  2185  10100.0  1240   \n",
       "\n",
       "       SP3  ...   BV3      SP4   SV4      BP4   BV4      SP5   SV5     BP5  \\\n",
       "0  10300.0  ...  1403  10350.0  2138  10000.0  2195  10400.0  2596  9990.0   \n",
       "1  10300.0  ...  1403  10350.0  2138  10000.0  2195  10400.0  2596  9990.0   \n",
       "2  10300.0  ...  1403  10350.0  2138  10000.0  2195  10400.0  2596  9990.0   \n",
       "3  10300.0  ...  1403  10350.0  2138  10000.0  2195  10400.0  2596  9990.0   \n",
       "4  10300.0  ...  1403  10350.0  2138  10000.0  2195  10400.0  2596  9990.0   \n",
       "\n",
       "   BV5  label  \n",
       "0  685      1  \n",
       "1  685      1  \n",
       "2  685      1  \n",
       "3  685      1  \n",
       "4  687      1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35c8c086-4f93-46f9-bc21-c161de0affdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data =  train_set.iloc[:int(np.floor(train_set.shape[0] * 0.8)),:]\n",
    "eval_data = train_set.iloc[int(np.floor(train_set.shape[0] * 0.8)):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fd6f6d9-62ee-4fb2-93fc-346e24f5660e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1732770, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>SP1</th>\n",
       "      <th>SV1</th>\n",
       "      <th>BP1</th>\n",
       "      <th>BV1</th>\n",
       "      <th>SP2</th>\n",
       "      <th>SV2</th>\n",
       "      <th>BP2</th>\n",
       "      <th>BV2</th>\n",
       "      <th>SP3</th>\n",
       "      <th>...</th>\n",
       "      <th>BV3</th>\n",
       "      <th>SP4</th>\n",
       "      <th>SV4</th>\n",
       "      <th>BP4</th>\n",
       "      <th>BV4</th>\n",
       "      <th>SP5</th>\n",
       "      <th>SV5</th>\n",
       "      <th>BP5</th>\n",
       "      <th>BV5</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>10200.0</td>\n",
       "      <td>3294</td>\n",
       "      <td>10150.0</td>\n",
       "      <td>61</td>\n",
       "      <td>10250.0</td>\n",
       "      <td>2185</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>1240</td>\n",
       "      <td>10300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1403</td>\n",
       "      <td>10350.0</td>\n",
       "      <td>2138</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2195</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>2596</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>685</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>10200.0</td>\n",
       "      <td>3294</td>\n",
       "      <td>10150.0</td>\n",
       "      <td>59</td>\n",
       "      <td>10250.0</td>\n",
       "      <td>2185</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>1240</td>\n",
       "      <td>10300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1403</td>\n",
       "      <td>10350.0</td>\n",
       "      <td>2138</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2195</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>2596</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>685</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>10200.0</td>\n",
       "      <td>3324</td>\n",
       "      <td>10150.0</td>\n",
       "      <td>59</td>\n",
       "      <td>10250.0</td>\n",
       "      <td>2185</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>1240</td>\n",
       "      <td>10300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1403</td>\n",
       "      <td>10350.0</td>\n",
       "      <td>2138</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2195</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>2596</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>685</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>10200.0</td>\n",
       "      <td>3324</td>\n",
       "      <td>10150.0</td>\n",
       "      <td>43</td>\n",
       "      <td>10250.0</td>\n",
       "      <td>2185</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>1240</td>\n",
       "      <td>10300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1403</td>\n",
       "      <td>10350.0</td>\n",
       "      <td>2138</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2195</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>2596</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>685</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>10200.0</td>\n",
       "      <td>3324</td>\n",
       "      <td>10150.0</td>\n",
       "      <td>43</td>\n",
       "      <td>10250.0</td>\n",
       "      <td>2185</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>1240</td>\n",
       "      <td>10300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1403</td>\n",
       "      <td>10350.0</td>\n",
       "      <td>2138</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2195</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>2596</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>687</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date      SP1   SV1      BP1  BV1      SP2   SV2      BP2   BV2  \\\n",
       "0  2021-06-01  10200.0  3294  10150.0   61  10250.0  2185  10100.0  1240   \n",
       "1  2021-06-01  10200.0  3294  10150.0   59  10250.0  2185  10100.0  1240   \n",
       "2  2021-06-01  10200.0  3324  10150.0   59  10250.0  2185  10100.0  1240   \n",
       "3  2021-06-01  10200.0  3324  10150.0   43  10250.0  2185  10100.0  1240   \n",
       "4  2021-06-01  10200.0  3324  10150.0   43  10250.0  2185  10100.0  1240   \n",
       "\n",
       "       SP3  ...   BV3      SP4   SV4      BP4   BV4      SP5   SV5     BP5  \\\n",
       "0  10300.0  ...  1403  10350.0  2138  10000.0  2195  10400.0  2596  9990.0   \n",
       "1  10300.0  ...  1403  10350.0  2138  10000.0  2195  10400.0  2596  9990.0   \n",
       "2  10300.0  ...  1403  10350.0  2138  10000.0  2195  10400.0  2596  9990.0   \n",
       "3  10300.0  ...  1403  10350.0  2138  10000.0  2195  10400.0  2596  9990.0   \n",
       "4  10300.0  ...  1403  10350.0  2138  10000.0  2195  10400.0  2596  9990.0   \n",
       "\n",
       "   BV5  label  \n",
       "0  685      1  \n",
       "1  685      1  \n",
       "2  685      1  \n",
       "3  685      1  \n",
       "4  687      1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce10698c-1642-4c54-8a03-a09d179a3d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(df,cols,norm):\n",
    "    #Normalizing using z-score\n",
    "    if norm=='Z':\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(df[cols])\n",
    "        data = scaler.transform(df[cols])\n",
    "    \n",
    "    \n",
    "    #Normalizing using DecPrec\n",
    "    if norm=='DecPrec':\n",
    "        k_len = np.ceil(np.log10(df[cols].abs().max()))\n",
    "        # print(k_len)\n",
    "        data = df[cols]/(10**k_len)\n",
    "\n",
    "    return data,scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dadfcd4d-9a50-4597-9aec-3d82d747458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input , scaler = normalize_data(train_data.iloc[:,1:-1],train_data.iloc[:,1:-1].columns,'Z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3e8fe98-861b-4472-978d-31ee5ff922b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1732770, 20)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f0b9052-fe98-40c5-a220-4eec520934b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_data.iloc[:,-1].to_numpy()\n",
    "eval_input = scaler.transform(eval_data.iloc[:,1:-1])\n",
    "eval_label = eval_data.iloc[:,-1].to_numpy()\n",
    "test_input = scaler.transform(test_data.iloc[:,1:-1])\n",
    "test_label = test_data.iloc[:,-1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67d55aa4-6322-46d6-ac8e-e44acd3b3448",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72256f72-b947-43d3-ae49-e221fa2c00b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "del [train_data,test_data,eval_data,df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0a76294-dd91-4ea4-8368-8f8fe35b1856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(eval_input).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4eb2b97-73e4-4db4-b080-9fe9a24db2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_LOB(data.Dataset):\n",
    "    \"\"\"Characterizes a dataset for PyTorch\"\"\"\n",
    "    def __init__(self, x,y, num_classes, T):\n",
    "        \"\"\"Initialization\"\"\" \n",
    "        # self.k = k\n",
    "        self.num_classes = num_classes\n",
    "        self.T = T\n",
    "            \n",
    "        # x = prepare_x(data)\n",
    "        # y = get_label(data)\n",
    "        x, y = data_classification(x, y, self.T)\n",
    "        # y = y[:,self.k] - 1\n",
    "        self.length = len(x)\n",
    "\n",
    "        x = torch.from_numpy(x)\n",
    "        self.x = torch.unsqueeze(x, 1)\n",
    "        self.y = torch.from_numpy(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the total number of samples\"\"\"\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generates samples of data\"\"\"\n",
    "        return self.x[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d092b6cf-0bb9-407b-ab87-d587cdaa4ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_classification(X, Y, T):\n",
    "    [N, D] = X.shape\n",
    "    # print(X.shape,T,N,Y.shape)\n",
    "    df = np.array(X)\n",
    "    # print(df.shape)\n",
    "    dY = np.array(Y)\n",
    "\n",
    "    dataY = dY[T - 1:N]\n",
    "\n",
    "    dataX = np.zeros((N - T + 1, T, D))\n",
    "    for i in range(T, N + 1):\n",
    "        dataX[i - T] = df[i - T:i, :]\n",
    "\n",
    "    return dataX, dataY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95d84451-a00b-4947-b27f-baa97e7b58ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "dataset_train = Dataset_LOB(train_input,train_label, num_classes=3, T=100)\n",
    "dataset_eval = Dataset_LOB(eval_input,eval_label, num_classes=3, T=100)\n",
    "dataset_test = Dataset_LOB(test_input,test_label, num_classes=3, T=100)\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19cc89a9-74e6-488e-ad6d-9f9ba4ec7eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=dataset_eval, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4d773e2-04eb-4931-be85-437c1f899239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1732671, 1, 100, 20]) torch.Size([282495])\n"
     ]
    }
   ],
   "source": [
    "print(dataset_train.x.shape, dataset_test.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83b9e4d6-d0d2-4d7c-9d69-eaf71da5ad0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000128"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(train_input)/1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "779db793-b4a5-4234-9fa6-3fcb9948a21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeing data\n",
    "# df=None\n",
    "# train_set = None\n",
    "# eval_data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e5d660c-33ea-4d4f-b52e-91f85d9b29d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.9308, -0.9392,  0.8519,  ..., -0.5216,  0.8641, -0.9638],\n",
      "          [ 0.9308, -0.9419,  0.8519,  ..., -0.5216,  0.8641, -0.9638],\n",
      "          [ 0.9308, -0.9409,  0.8519,  ..., -0.5216,  0.8641, -0.9638],\n",
      "          ...,\n",
      "          [ 0.9308, -0.7869,  0.8519,  ..., -0.5645,  0.8641, -0.9653],\n",
      "          [ 0.9308, -0.7869,  0.8519,  ..., -0.5645,  0.8641, -0.9653],\n",
      "          [ 0.9308, -0.7869,  0.8519,  ..., -0.5645,  0.8641, -0.9653]]]],\n",
      "       dtype=torch.float64)\n",
      "tensor([1])\n",
      "torch.Size([1, 1, 100, 20]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "tmp_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=1, shuffle=True)\n",
    "\n",
    "for x, y in tmp_loader:\n",
    "    print(x)\n",
    "    print(y)\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "293110f5-5d35-42f7-9b73-e2d270f1d372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019377999999999992 mb\n"
     ]
    }
   ],
   "source": [
    "# from pympler import asizeof\n",
    "s=0\n",
    "for key,obj in locals().items():\n",
    "    cc= sys.getsizeof(obj)/1000000\n",
    "    s+=cc\n",
    "    if cc>20:\n",
    "        print(key,cc)\n",
    "print(s,'mb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f6211f2-92a0-4a0d-b5d2-075354d408ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")\n",
    "\n",
    "device = mps_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0d93cf5-9b13-4c4c-aa40-7c52aa206a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class deeplob(nn.Module):\n",
    "    def __init__(self, y_len):\n",
    "        super().__init__()\n",
    "        self.y_len = y_len\n",
    "        \n",
    "        # convolution blocks\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(1,2), stride=(1,2)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "#             nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(1,2), stride=(1,2)),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(1,5)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        \n",
    "        # inception moduels\n",
    "        self.inp1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        self.inp2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(5,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        self.inp3 = nn.Sequential(\n",
    "            nn.MaxPool2d((3, 1), stride=(1, 1), padding=(1, 0)),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        \n",
    "        # lstm layers\n",
    "        self.lstm = nn.LSTM(input_size=192, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        self.fc1 = nn.Linear(64, self.y_len)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # h0: (number of hidden layers, batch size, hidden size)\n",
    "        h0 = torch.zeros(1, x.size(0), 64).to(device)\n",
    "        c0 = torch.zeros(1, x.size(0), 64).to(device)\n",
    "    \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        x_inp1 = self.inp1(x)\n",
    "        x_inp2 = self.inp2(x)\n",
    "        x_inp3 = self.inp3(x)  \n",
    "        \n",
    "        x = torch.cat((x_inp1, x_inp2, x_inp3), dim=1)\n",
    "        \n",
    "#         x = torch.transpose(x, 1, 2)\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        x = torch.reshape(x, (-1, x.shape[1], x.shape[2]))\n",
    "        \n",
    "        x, _ = self.lstm(x, (h0, c0))\n",
    "        x = x[:, -1, :]\n",
    "        x = self.fc1(x)\n",
    "        forecast_y = torch.softmax(x, dim=1)\n",
    "        \n",
    "        return forecast_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31ea6158-68b0-4801-937a-1132949a89d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = deeplob(y_len = dataset_train.num_classes)\n",
    "model.to(mps_device)\n",
    "device = mps_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "851d0949-4bcf-48a9-bf35-0b75beb5c236",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "# state_dict = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a871d3f4-d0fd-4889-9525-ad32ac70c1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gd(model, criterion, optimizer, train_loader, test_loader, epochs):\n",
    "    global state_dict\n",
    "    train_losses = np.zeros(epochs)\n",
    "    test_losses = np.zeros(epochs)\n",
    "    best_test_loss = np.inf\n",
    "    best_test_epoch = 0\n",
    "\n",
    "    for it in tqdm(range(epochs)):\n",
    "        \n",
    "        model.train()\n",
    "        t0 = datetime.now()\n",
    "        train_loss = []\n",
    "        for inputs, targets in train_loader:\n",
    "            # move data to GPU\n",
    "            inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            # print(\"about to get model output\")\n",
    "            outputs = model(inputs)\n",
    "            # print(\"done getting model output\")\n",
    "            # print(\"outputs.shape:\", outputs.shape, \"targets.shape:\", targets.shape)\n",
    "            loss = criterion(outputs, targets)\n",
    "            # Backward and optimize\n",
    "            # print(\"about to optimize\")\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())\n",
    "        # Get train loss and test loss\n",
    "        train_loss = np.mean(train_loss) # a little misleading\n",
    "    \n",
    "        model.eval()\n",
    "        test_loss = []\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)      \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss.append(loss.item())\n",
    "        test_loss = np.mean(test_loss)\n",
    "\n",
    "        # Save losses\n",
    "        train_losses[it] = train_loss\n",
    "        test_losses[it] = test_loss\n",
    "        \n",
    "        if test_loss < best_test_loss:\n",
    "            # state_dict = copy.deepcopy(model.state_dict())\n",
    "            torch.save(model, '/Users/jandh/Desktop/Old Desktop/od/1 quater/Project Lab/best_val_5level_model_pytorch')\n",
    "            best_test_loss = test_loss\n",
    "            best_test_epoch = it\n",
    "            print('model saved')\n",
    "\n",
    "        dt = datetime.now() - t0\n",
    "        print(dt)\n",
    "        print(f'Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, \\\n",
    "          Validation Loss: {test_loss:.4f}, Duration: {dt}, Best Val Epoch: {best_test_epoch}')\n",
    "\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a146bd0-98ee-48b5-b47c-3d630e251ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████                                    | 1/10 [41:28<6:13:13, 2488.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "0:41:28.154958\n",
      "Epoch 1/10, Train Loss: 0.6752,           Validation Loss: 0.7554, Duration: 0:41:28.154958, Best Val Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████▌                              | 2/10 [2:12:04<9:22:59, 4222.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:30:36.317609\n",
      "Epoch 2/10, Train Loss: 0.6737,           Validation Loss: 0.7554, Duration: 1:30:36.317609, Best Val Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████▍                          | 3/10 [2:41:33<6:01:53, 3101.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:29:28.526023\n",
      "Epoch 3/10, Train Loss: 0.6737,           Validation Loss: 0.7554, Duration: 0:29:28.526023, Best Val Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████▏                      | 4/10 [3:12:22<4:20:43, 2607.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:30:49.079999\n",
      "Epoch 4/10, Train Loss: 0.6737,           Validation Loss: 0.7554, Duration: 0:30:49.079999, Best Val Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████                   | 5/10 [3:43:17<3:14:40, 2336.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:30:55.190691\n",
      "Epoch 5/10, Train Loss: 0.6737,           Validation Loss: 0.7554, Duration: 0:30:55.190691, Best Val Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████▊               | 6/10 [4:14:13<2:24:52, 2173.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:30:56.468726\n",
      "Epoch 6/10, Train Loss: 0.6737,           Validation Loss: 0.7554, Duration: 0:30:56.468726, Best Val Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████▌           | 7/10 [4:45:20<1:43:39, 2073.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:31:07.114210\n",
      "Epoch 7/10, Train Loss: 0.6737,           Validation Loss: 0.7554, Duration: 0:31:07.114210, Best Val Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████▍       | 8/10 [5:16:25<1:06:53, 2006.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:31:04.358482\n",
      "Epoch 8/10, Train Loss: 0.6737,           Validation Loss: 0.7554, Duration: 0:31:04.358482, Best Val Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████    | 9/10 [5:47:22<32:40, 1960.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:30:57.542389\n",
      "Epoch 9/10, Train Loss: 0.6737,           Validation Loss: 0.7554, Duration: 0:30:57.542389, Best Val Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 10/10 [6:18:23<00:00, 2270.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:31:00.542859\n",
      "Epoch 10/10, Train Loss: 0.6737,           Validation Loss: 0.7554, Duration: 0:31:00.542859, Best Val Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = batch_gd(model, criterion, optimizer, \n",
    "                                    train_loader, val_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f76845ea-b420-4ad7-9ce1-ce2ed0f1bc9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x157eaffe0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(val_losses, label='validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3db7c9b-da0f-479b-a26d-c0a259610bc7",
   "metadata": {},
   "source": [
    "## Model_Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "84af9f8a-e3cd-4d48-885b-379dc307e03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.8505\n"
     ]
    }
   ],
   "source": [
    "n_correct = 0.\n",
    "n_total = 0.\n",
    "for inputs, targets in test_loader:\n",
    "    # Move to GPU\n",
    "    inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Get prediction\n",
    "    # torch.max returns both max and argmax\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "    # update counts\n",
    "    n_correct += (predictions == targets).sum().item()\n",
    "    n_total += targets.shape[0]\n",
    "\n",
    "test_acc = n_correct / n_total\n",
    "print(f\"Test acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e0709ef-2757-4773-9d1a-7300502b6cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_targets = []\n",
    "all_predictions = []\n",
    "\n",
    "for inputs, targets in test_loader:\n",
    "    # Move to GPU\n",
    "    inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Get prediction\n",
    "    # torch.max returns both max and argmax\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "    all_targets.append(targets.cpu().numpy())\n",
    "    all_predictions.append(predictions.cpu().numpy())\n",
    "\n",
    "all_targets = np.concatenate(all_targets)    \n",
    "all_predictions = np.concatenate(all_predictions)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9e9bd829-9998-428a-af34-dd1a9942c0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.8505354077063311\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000     22858\n",
      "           1     0.8505    1.0000    0.9192    240272\n",
      "           2     0.0000    0.0000    0.0000     19365\n",
      "\n",
      "    accuracy                         0.8505    282495\n",
      "   macro avg     0.2835    0.3333    0.3064    282495\n",
      "weighted avg     0.7234    0.8505    0.7818    282495\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dawai/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/dawai/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/dawai/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print('accuracy_score:', accuracy_score(all_targets, all_predictions))\n",
    "print(classification_report(all_targets, all_predictions, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "771a2514-bcf3-4d44-b404-9f69fca4008f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vf/gw1t6f4j3mv84kp8kpw4j_bw0000gn/T/ipykernel_29737/3214504261.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load('/Users/jandh/Desktop/Old Desktop/od/1 quater/Project Lab/best_val_5level_model_pytorch')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "deeplob(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(1, 2), stride=(1, 2))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.01)\n",
       "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 2))\n",
       "    (1): Tanh()\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (4): Tanh()\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (7): Tanh()\n",
       "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.01)\n",
       "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (inp1): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=same)\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (inp2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=same)\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (inp3): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)\n",
       "    (1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (lstm): LSTM(192, 64, batch_first=True)\n",
       "  (fc1): Linear(in_features=64, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = deeplob(y_len = dataset_train.num_classes)\n",
    "model = torch.load('/Users/jandh/Desktop/Old Desktop/od/1 quater/Project Lab/best_val_5level_model_pytorch')\n",
    "model.to(mps_device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "492617d1-fae2-4047-b859-265747cee5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load('best_val_model_pytorch')\n",
    "all_targets = []\n",
    "all_predictions = []\n",
    "\n",
    "for inputs, targets in train_loader:\n",
    "    # Move to GPU\n",
    "    inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Get prediction\n",
    "    # torch.max returns both max and argmax\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "    all_targets.append(targets.cpu().numpy())\n",
    "    all_predictions.append(predictions.cpu().numpy())\n",
    "\n",
    "all_targets = np.concatenate(all_targets)    \n",
    "all_predictions = np.concatenate(all_predictions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4daa63f2-5a1b-487f-b7c5-4b904a7ea67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.8777667543347814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dawai/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/dawai/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000    110877\n",
      "           1     0.8778    1.0000    0.9349   1520881\n",
      "           2     0.0000    0.0000    0.0000    100913\n",
      "\n",
      "    accuracy                         0.8778   1732671\n",
      "   macro avg     0.2926    0.3333    0.3116   1732671\n",
      "weighted avg     0.7705    0.8778    0.8206   1732671\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dawai/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print('accuracy_score:', accuracy_score(all_targets, all_predictions))\n",
    "print(classification_report(all_targets, all_predictions, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3840b1d3-8847-435e-b133-a9b9d4324772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
