{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29066cf5-f906-471b-94ea-180f4f22fe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torchinfo import summary\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42f9a4f6-6d34-4017-947d-a3a45b2e69f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macOS-14.6-arm64-arm-64bit\n"
     ]
    }
   ],
   "source": [
    "import platform; print(platform.platform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1a59676-4fcc-47e0-b310-e79beb1cf2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e47a1ee-9cea-47ea-910b-a067c76e46f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_classification(X, Y, T):\n",
    "    [N, D] = X.shape\n",
    "    # print(X.shape,T,N,Y.shape)\n",
    "    df = np.array(X)\n",
    "    # print(df.shape)\n",
    "    dY = np.array(Y)\n",
    "\n",
    "    dataY = dY[T - 1:N]\n",
    "\n",
    "    dataX = np.zeros((N - T + 1, T, D))\n",
    "    for i in range(T, N + 1):\n",
    "        dataX[i - T] = df[i - T:i, :]\n",
    "\n",
    "    return dataX, dataY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "315c7403-8f35-4df8-9f84-8a0676281c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = mps_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2bd9bed-e37f-40df-829f-fe8addca3140",
   "metadata": {},
   "outputs": [],
   "source": [
    "class deeplob(nn.Module):\n",
    "    def __init__(self, y_len):\n",
    "        super().__init__()\n",
    "        self.y_len = y_len\n",
    "        \n",
    "        # convolution blocks\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(1,2), stride=(1,2)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "#             nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(1,2), stride=(1,2)),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(1,10)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        \n",
    "        # inception moduels\n",
    "        self.inp1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        self.inp2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(5,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        self.inp3 = nn.Sequential(\n",
    "            nn.MaxPool2d((3, 1), stride=(1, 1), padding=(1, 0)),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        \n",
    "        # lstm layers\n",
    "        self.lstm = nn.LSTM(input_size=192, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        self.fc1 = nn.Linear(64, self.y_len)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # h0: (number of hidden layers, batch size, hidden size)\n",
    "        h0 = torch.zeros(1, x.size(0), 64).to(device)\n",
    "        c0 = torch.zeros(1, x.size(0), 64).to(device)\n",
    "    \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        x_inp1 = self.inp1(x)\n",
    "        x_inp2 = self.inp2(x)\n",
    "        x_inp3 = self.inp3(x)  \n",
    "        \n",
    "        x = torch.cat((x_inp1, x_inp2, x_inp3), dim=1)\n",
    "        \n",
    "#         x = torch.transpose(x, 1, 2)\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        x = torch.reshape(x, (-1, x.shape[1], x.shape[2]))\n",
    "        \n",
    "        x, _ = self.lstm(x, (h0, c0))\n",
    "        x = x[:, -1, :]\n",
    "        x = self.fc1(x)\n",
    "        forecast_y = torch.softmax(x, dim=1)\n",
    "        \n",
    "        return forecast_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b9023d9-0dbd-4f21-9c65-979a98957a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vf/gw1t6f4j3mv84kp8kpw4j_bw0000gn/T/ipykernel_12291/1128726781.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load('/Users/jandh/Desktop/Old Desktop/od/1 quater/Project Lab/best_val_model_pytorch')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "deeplob(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(1, 2), stride=(1, 2))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.01)\n",
       "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 2))\n",
       "    (1): Tanh()\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (4): Tanh()\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (7): Tanh()\n",
       "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(1, 10), stride=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.01)\n",
       "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (inp1): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=same)\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (inp2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=same)\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (inp3): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)\n",
       "    (1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (lstm): LSTM(192, 64, batch_first=True)\n",
       "  (fc1): Linear(in_features=64, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('/Users/jandh/Desktop/Old Desktop/od/1 quater/Project Lab/best_val_model_pytorch')\n",
    "model.to(mps_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c533816-e0eb-4b8a-a645-2c6dc9aec34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_LOBSTER(data.Dataset):\n",
    "    \"\"\"Characterizes a dataset for PyTorch\"\"\"\n",
    "    def __init__(self, x,y, num_classes, T):\n",
    "        \"\"\"Initialization\"\"\" \n",
    "        # self.k = k\n",
    "        self.num_classes = num_classes\n",
    "        self.T = T\n",
    "            \n",
    "        # x = prepare_x(data)\n",
    "        # y = get_label(data)\n",
    "        x, y = data_classification(x, y, self.T)\n",
    "        # y = y[:,self.k] - 1\n",
    "        self.length = len(x)\n",
    "\n",
    "        x = torch.from_numpy(x)\n",
    "        self.x = torch.unsqueeze(x, 1)\n",
    "        self.y = torch.from_numpy(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the total number of samples\"\"\"\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generates samples of data\"\"\"\n",
    "        return self.x[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "459adfd6-b15f-4a2c-827a-f7a1a15953a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data_quantile(test_data,norm,q=0.995):\n",
    "    '''quantile based threshold for labelling 999%'''\n",
    "    test_data = test_data.astype(np.float64)\n",
    "    for i in range(0,40,2):\n",
    "        if i%2==0:\n",
    "            test_data.loc[:,i] = test_data.loc[:,i]/10000\n",
    "    # print(test_data.head())\n",
    "    \n",
    "    #Creating labels of the data\n",
    "    mid_Price = (test_data.iloc[:,0]+test_data.iloc[:,2])/2\n",
    "    foward_mean = mid_Price[::-1].rolling(window = 10,min_periods = 10).mean()[::-1].shift(-1)\n",
    "    pc_mid = (foward_mean-mid_Price)/mid_Price\n",
    "\n",
    "    up = pc_mid.quantile(q)\n",
    "    down = pc_mid.quantile(1-q)\n",
    "    print(f\"upvalue= {up:.4%} , downvalue = {down:.4%} \")\n",
    "    labels = pc_mid.copy(deep=True)\n",
    "    labels.loc[(pc_mid<up) & (pc_mid>down)] = 1\n",
    "    labels.loc[pc_mid>=up] = 0\n",
    "    labels.loc[pc_mid<=down] = 2\n",
    "\n",
    "    print(labels.unique(),labels.value_counts(),'labels distribution')\n",
    "    #Normalizing using z-score\n",
    "    if norm=='Z':\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(test_data)\n",
    "        test_data = scaler.transform(test_data)\n",
    "\n",
    "    #Normalizing using DecPrec\n",
    "    if norm=='DecPrec':\n",
    "        k_len = np.ceil(np.log10(test_data.abs().max()))\n",
    "        # print(k_len)\n",
    "        test_data = test_data/(10**k_len)\n",
    "    # test\n",
    "    # print(pc_mid.iloc[-10],pc_mid.iloc[-11])\n",
    "    return test_data[:-10].to_numpy(),labels[:-10].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c8f9929d-94ac-48e9-87dd-957d84792034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data_lobster(test_data,norm):\n",
    "\n",
    "    '''Fixed threshold for labelling 20bps'''\n",
    "    \n",
    "    test_data = test_data.astype(np.float64)\n",
    "    for i in range(0,40,2):\n",
    "        if i%2==0:\n",
    "            test_data.loc[:,i] = test_data.loc[:,i]/10000\n",
    "    # print(test_data.head())\n",
    "    def label_thresholder(x):\n",
    "        if x>=0.002:\n",
    "            return 0\n",
    "        elif x<=-0.002:\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "    #Creating labels of the data\n",
    "    mid_Price = (test_data.iloc[:,0]+test_data.iloc[:,2])/2\n",
    "    foward_mean = mid_Price[::-1].rolling(window = 10,min_periods = 10).mean()[::-1].shift(-1)\n",
    "    pc_mid = (foward_mean-mid_Price)/mid_Price\n",
    "    # print(pc_mid.mean(),pc_mid.min(),pc_mid.max(),mid_Price)\n",
    "    labels = pc_mid.apply(label_thresholder)\n",
    "    print(labels.unique(),labels.value_counts(),'labels distribution')\n",
    "    #Normalizing using z-score\n",
    "    if norm=='Z':\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(test_data)\n",
    "        test_data = scaler.transform(test_data)\n",
    "\n",
    "    #Normalizing using DecPrec\n",
    "    if norm=='DecPrec':\n",
    "        k_len = np.ceil(np.log10(test_data.abs().max()))\n",
    "        # print(k_len)\n",
    "        test_data = test_data/(10**k_len)\n",
    "    # test\n",
    "    # print(pc_mid.iloc[-10],pc_mid.iloc[-11])\n",
    "    return test_data[:-10].to_numpy(),labels[:-10].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "59e887de-6a3c-4664-9331-0ded0bc5503a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generic_test(test_data,name,prep_data,q=0.995):\n",
    "    '''process inputs and score inputs on targets'''\n",
    "    if prep_data.__name__=='prep_data_lobster':\n",
    "        inputs, targets = prep_data(test_data,norm='DecPrec')\n",
    "\n",
    "    elif prep_data.__name__=='prep_data_quantile':\n",
    "        inputs, targets = prep_data(test_data,norm='DecPrec',q=q)\n",
    "        \n",
    "    # test_data = pd.read_excel(location,header=None)\n",
    "    \n",
    "    # col = 21\n",
    "    # print(inputs[:,col].mean(),np.median(inputs[:,col]),inputs[:,col].max(),inputs[:,col].min(),inputs.shape)\n",
    "    batch_size = 32\n",
    "    dataset_test = Dataset_LOBSTER(inputs,targets, num_classes=3, T=100)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=False)\n",
    "    # tmp_loader = torch.utils.data.DataLoader(dataset=dataset_test, batch_size=1, shuffle=True)\n",
    "    \n",
    "    # for x, y in tmp_loader:\n",
    "    #     print(x)\n",
    "    #     print(y)\n",
    "    #     print(x.shape, y.shape)\n",
    "    #     break\n",
    "    n_correct = 0.\n",
    "    n_total = 0.\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "    for inputs, targets in test_loader:\n",
    "        # Move to GPU\n",
    "        model.eval()\n",
    "        inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
    "    \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Get prediction\n",
    "        # torch.max returns both max and argmax\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "    \n",
    "        # update counts\n",
    "        n_correct += (predictions == targets).sum().item()\n",
    "        n_total += targets.shape[0]\n",
    "\n",
    "        all_targets.append(targets.cpu().numpy())\n",
    "        all_predictions.append(predictions.cpu().numpy())\n",
    "    \n",
    "    test_acc = n_correct / n_total\n",
    "    print(f\"Test acc of {name}_dataset: {test_acc:.4f}\\n\")\n",
    "    all_targets = np.concatenate(all_targets)    \n",
    "    all_predictions = np.concatenate(all_predictions)\n",
    "    print('accuracy_score:', accuracy_score(all_targets, all_predictions))\n",
    "    print(classification_report(all_targets, all_predictions, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "51ba1789-6764-44f9-9023-a4665df62d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = '/Users/jandh/Desktop/Old Desktop/od/1 quater/Project Lab/AMZN_2012-06-21_34200000_57600000_orderbook_10.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "896594dc-e3d1-4905-81e1-eadaa96a4d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_excel(location,header=None)\n",
    "# inputs, targets = prep_data(test_data,norm='DecPrec')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf60447f-b7bf-47ef-aa9f-8b1a3d1d35b6",
   "metadata": {},
   "source": [
    "AMAZON LOBSTER TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e6445723-7492-43bf-be1f-4330e5a6c615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 1    269748\n",
      "Name: count, dtype: int64 labels distribution\n",
      "Test acc of Amazon_dataset: 0.6754\n",
      "\n",
      "accuracy_score: 0.6753585349300361\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         0\n",
      "           1     1.0000    0.6754    0.8062    269639\n",
      "           2     0.0000    0.0000    0.0000         0\n",
      "\n",
      "    accuracy                         0.6754    269639\n",
      "   macro avg     0.3333    0.2251    0.2687    269639\n",
      "weighted avg     1.0000    0.6754    0.8062    269639\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dawai/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/dawai/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/dawai/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "Generic_test(test_data,'Amazon',prep_data_lobster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8e9df3a5-0bec-4838-82d5-94a45ae6f8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upvalue= 0.0201% , downvalue = -0.0200% \n",
      "[ 0.  1.  2. nan] 1.0    267040\n",
      "0.0      1349\n",
      "2.0      1349\n",
      "Name: count, dtype: int64 labels distribution\n",
      "Test acc of Amazon_dataset: 0.6716\n",
      "\n",
      "accuracy_score: 0.6716350379581588\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0064    0.1190    0.0122      1344\n",
      "           1     0.9915    0.6763    0.8041    266946\n",
      "           2     0.0062    0.2898    0.0122      1349\n",
      "\n",
      "    accuracy                         0.6716    269639\n",
      "   macro avg     0.3347    0.3617    0.2762    269639\n",
      "weighted avg     0.9816    0.6716    0.7962    269639\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Generic_test(test_data,'Amazon',prep_data_quantile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8be599-73df-4039-9ef9-f252fd214465",
   "metadata": {},
   "source": [
    "APPLE TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b7a8ae6c-1fa3-4b9f-86d1-1aa263a0645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = '/Users/jandh/Desktop/Old Desktop/od/1 quater/Project Lab/AAPL_2012-06-21_34200000_57600000_orderbook_10.xlsx'\n",
    "test_data = pd.read_excel(location,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6a5e005f-7c5a-42bc-b24a-d567eea16c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 1    400391\n",
      "Name: count, dtype: int64 labels distribution\n",
      "Test acc of Apple_dataset: 0.9654\n",
      "\n",
      "accuracy_score: 0.9653544251302831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dawai/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/dawai/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/dawai/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         0\n",
      "           1     1.0000    0.9654    0.9824    400282\n",
      "           2     0.0000    0.0000    0.0000         0\n",
      "\n",
      "    accuracy                         0.9654    400282\n",
      "   macro avg     0.3333    0.3218    0.3275    400282\n",
      "weighted avg     1.0000    0.9654    0.9824    400282\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Generic_test(test_data,'Apple',prep_data_lobster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6030a62e-7d51-4118-abbf-80d802fc5dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upvalue= 0.0107% , downvalue = -0.0109% \n",
      "[ 1.  0.  2. nan] 1.0    396377\n",
      "0.0      2002\n",
      "2.0      2002\n",
      "Name: count, dtype: int64 labels distribution\n",
      "Test acc of Apple_dataset: 0.9566\n",
      "\n",
      "accuracy_score: 0.9566105895343783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0113    0.0787    0.0198      1995\n",
      "           1     0.9905    0.9659    0.9780    396286\n",
      "           2     0.1071    0.0015    0.0030      2001\n",
      "\n",
      "    accuracy                         0.9566    400282\n",
      "   macro avg     0.3697    0.3487    0.3336    400282\n",
      "weighted avg     0.9812    0.9566    0.9684    400282\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Generic_test(test_data,'Apple',prep_data_quantile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a09a1b-2492-478b-b190-645c748c2e0b",
   "metadata": {},
   "source": [
    "MSFT TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "300a7ece-16fd-4276-911d-dc05dcb7b0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 1    668765\n",
      "Name: count, dtype: int64 labels distribution\n",
      "Test acc of MSFT_dataset: 0.9933\n",
      "\n",
      "accuracy_score: 0.993265595463138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dawai/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/dawai/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/dawai/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         0\n",
      "           1     1.0000    0.9933    0.9966    668656\n",
      "           2     0.0000    0.0000    0.0000         0\n",
      "\n",
      "    accuracy                         0.9933    668656\n",
      "   macro avg     0.3333    0.3311    0.3322    668656\n",
      "weighted avg     1.0000    0.9933    0.9966    668656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "location = '/Users/jandh/Desktop/Old Desktop/od/1 quater/Project Lab/MSFT_2012-06-21_34200000_57600000_orderbook_10.xlsx'\n",
    "test_data = pd.read_excel(location,header=None)\n",
    "Generic_test(test_data,'MSFT',prep_data_lobster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "966f0439-654d-49d8-9d53-b62f98f44659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upvalue= 0.0146% , downvalue = -0.0147% \n",
      "[ 1.  2.  0. nan] 1.0    662063\n",
      "2.0      3347\n",
      "0.0      3345\n",
      "Name: count, dtype: int64 labels distribution\n",
      "Test acc of MSFT_dataset: 0.9836\n",
      "\n",
      "accuracy_score: 0.9836268574573472\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0202    0.0132    0.0160      3334\n",
      "           1     0.9902    0.9934    0.9918    661981\n",
      "           2     0.0146    0.0102    0.0120      3341\n",
      "\n",
      "    accuracy                         0.9836    668656\n",
      "   macro avg     0.3417    0.3389    0.3399    668656\n",
      "weighted avg     0.9805    0.9836    0.9820    668656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Generic_test(test_data,'MSFT',prep_data_quantile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ffeb50-a606-43b0-b451-d962fe4d70d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
